{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from config import CONFIG\n",
    "\n",
    "folder_path = CONFIG[\"train_data_folder\"]\n",
    "save_path = CONFIG[\"processed_dataset_path\"]\n",
    "use_datetime_index = CONFIG[\"use_datetime_index\"]\n",
    "normalization_mode = CONFIG[\"normalization_mode\"]\n",
    "percentile_value = CONFIG.get(\"percentile_value\", 95)  # optional if using percentile\n",
    "history_len = CONFIG[\"history_len\"]\n",
    "predict_len = CONFIG[\"predict_len\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6549f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script loads multiple CSV files from a specified folder, stacks them into a single tensor, and creates sliding windows for time series data.\n",
    "def load_and_stack_csvs(folder_path, use_datetime_index=False):\n",
    "    feature_list = []\n",
    "    index_ref = None\n",
    "\n",
    "    # Loop over all CSVs in the folder\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(path)\n",
    "\n",
    "            # If datetime indexing is desired\n",
    "            if use_datetime_index:\n",
    "                # Assume first column is datetime if exists\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df.iloc[:,0]):\n",
    "                    df.iloc[:,0] = pd.to_datetime(df.iloc[:,0])\n",
    "\n",
    "                df = df.set_index(df.columns[0])\n",
    "\n",
    "            else:\n",
    "                # Integer index\n",
    "                df.index = pd.RangeIndex(len(df))\n",
    "\n",
    "            # Set reference index on first file\n",
    "            if index_ref is None:\n",
    "                index_ref = df.index\n",
    "            else:\n",
    "                # Check if index matches\n",
    "                if not df.index.equals(index_ref):\n",
    "                    raise ValueError(f\"Index mismatch between files! {filename}\")\n",
    "\n",
    "            # Check only 1 feature column (after index)\n",
    "            if df.shape[1] != 1:\n",
    "                raise ValueError(f\"Expected 1 feature column in {filename}, found {df.shape[1]}.\")\n",
    "\n",
    "            feature_list.append(torch.tensor(df.iloc[:,0].values, dtype=torch.float32))  # shape [T]\n",
    "\n",
    "    # Stack features along last dimension\n",
    "    stacked = torch.stack(feature_list, dim=-1)  # [T, n_features]\n",
    "\n",
    "    print(f\"âœ… Loaded {len(feature_list)} features, stacked shape: {stacked.shape}\")\n",
    "\n",
    "    return stacked, index_ref\n",
    "\n",
    "def create_sliding_windows(stacked_tensor, history_len, predict_len):\n",
    "    total_seq_len = history_len + predict_len\n",
    "    num_samples = stacked_tensor.shape[0] - total_seq_len + 1\n",
    "\n",
    "    windows = []\n",
    "    for i in range(num_samples):\n",
    "        window = stacked_tensor[i : i + total_seq_len]  # [total_seq_len, n_features]\n",
    "        windows.append(window)\n",
    "\n",
    "    windows = torch.stack(windows, dim=0)  # [num_samples, total_seq_len, n_features]\n",
    "\n",
    "    print(f\"âœ… Created {windows.shape[0]} sliding windows.\")\n",
    "\n",
    "    return windows\n",
    "\n",
    "def calculate_normalization_params(stacked_tensor, mode=\"max\", percentile_value=95):\n",
    "    \"\"\"\n",
    "    Calculate normalization parameters based on chosen mode.\n",
    "    \"\"\"\n",
    "    norm_params = {}\n",
    "\n",
    "    if mode == \"max\":\n",
    "        values = stacked_tensor.abs().max(dim=0)[0]\n",
    "        norm_params = {\"type\": \"max\", \"values\": values}\n",
    "\n",
    "    elif mode == \"standard\":\n",
    "        mean = stacked_tensor.mean(dim=0)\n",
    "        std = stacked_tensor.std(dim=0) + 1e-8\n",
    "        norm_params = {\"type\": \"standard\", \"mean\": mean, \"std\": std}\n",
    "\n",
    "    elif mode == \"percentile\":\n",
    "        values = torch.quantile(stacked_tensor, percentile_value / 100.0, dim=0)\n",
    "        norm_params = {\"type\": \"percentile\", \"percentile\": values}\n",
    "\n",
    "    elif mode == \"exp\":\n",
    "        norm_params = {\"type\": \"exp\"}\n",
    "\n",
    "    elif mode == \"none\":\n",
    "        norm_params = {\"type\": \"none\"}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization mode: {mode}\")\n",
    "\n",
    "    print(f\"ðŸ”µ Calculated '{mode}' normalization parameters.\")\n",
    "    return norm_params\n",
    "\n",
    "\n",
    "def apply_normalization(stacked_tensor, norm_params, mode=\"max\"):\n",
    "    \"\"\"\n",
    "    Apply normalization to stacked tensor.\n",
    "    \"\"\"\n",
    "    if mode == \"max\":\n",
    "        norm_values = norm_params[\"values\"]\n",
    "        normalized = stacked_tensor / (norm_values + 1e-8)\n",
    "\n",
    "    elif mode == \"standard\":\n",
    "        mean = norm_params[\"mean\"]\n",
    "        std = norm_params[\"std\"]\n",
    "        normalized = (stacked_tensor - mean) / (std + 1e-8)\n",
    "\n",
    "    elif mode == \"percentile\":\n",
    "        norm_values = norm_params[\"percentile\"]\n",
    "        normalized = stacked_tensor / (norm_values + 1e-8)\n",
    "\n",
    "    elif mode == \"exp\":\n",
    "        normalized = torch.log(stacked_tensor + 1e-8)\n",
    "\n",
    "    elif mode == \"none\":\n",
    "        normalized = stacked_tensor\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization mode: {mode}\")\n",
    "\n",
    "    print(f\"ðŸ”µ Applied '{mode}' normalization.\")\n",
    "    return normalized\n",
    "\n",
    "# Example usage:\n",
    "# stacked, index_ref = load_and_stack_csvs(\"./training_data\", use_datetime_index=True)\n",
    "# windows = create_sliding_windows(stacked, history_len=50, predict_len=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and stack features\n",
    "stacked_tensor, index_ref = load_and_stack_csvs(folder_path, use_datetime_index)\n",
    "\n",
    "# Step 2: Calculate normalization parameters\n",
    "norm_params = calculate_normalization_params(stacked_tensor, mode=normalization_mode, percentile_value=percentile_value)\n",
    "\n",
    "# Step 3: Apply normalization\n",
    "stacked_tensor = apply_normalization(stacked_tensor, norm_params, mode=normalization_mode)\n",
    "\n",
    "# Step 4: Preroll into sliding windows\n",
    "windows = create_sliding_windows(stacked_tensor, history_len, predict_len)\n",
    "\n",
    "# Step 5: Save dataset\n",
    "save_dict = {\n",
    "    \"windows\": windows,\n",
    "    \"norm_params\": norm_params,\n",
    "    \"normalization_mode\": normalization_mode,\n",
    "    \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(save_dict, save_path)\n",
    "\n",
    "print(f\"âœ… Saved processed dataset at: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
