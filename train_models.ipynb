{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fb0410",
   "metadata": {},
   "source": [
    "# Conditional Diffusion Training\n",
    "Train a transformer-based conditional diffusion model for time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bec91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import ConditionalScoreNet\n",
    "from data import generate_sine_sequence\n",
    "from trainer import train_diffusion_model_conditional\n",
    "from sde import VPSDE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_samples = 5000\n",
    "history_len = 150\n",
    "predict_len = 50\n",
    "total_len = history_len + predict_len\n",
    "input_dim = 1\n",
    "batch_size = 128\n",
    "num_epochs = 500\n",
    "lr = 1e-4\n",
    "num_diffusion_timesteps = 1000\n",
    "checkpoint_path = \"checkpoints/score_model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5acb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([5000, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "# Generate sine sequences\n",
    "data = generate_sine_sequence(num_samples, total_len, input_dim=input_dim)\n",
    "print(\"Data shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068bd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalScoreNet(input_dim=input_dim,\n",
    "                            history_len=history_len,\n",
    "                            predict_len=predict_len).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f58088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 100/500 [28:30<2:01:18, 18.20s/it, loss=9.6064]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to checkpoints/score_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 200/500 [58:53<1:30:51, 18.17s/it, loss=10.2140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to checkpoints/score_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 300/500 [1:29:19<1:01:00, 18.30s/it, loss=9.7592] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to checkpoints/score_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 400/500 [1:58:22<30:22, 18.23s/it, loss=9.9139]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to checkpoints/score_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  81%|████████  | 403/500 [1:59:25<28:44, 17.78s/it, loss=9.3811]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_diffusion_model_conditional(\n\u001b[0;32m      2\u001b[0m     data_x\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m      3\u001b[0m     score_net\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m      5\u001b[0m     num_diffusion_timesteps\u001b[38;5;241m=\u001b[39mnum_diffusion_timesteps,\n\u001b[0;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      7\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[0;32m      8\u001b[0m     history_len\u001b[38;5;241m=\u001b[39mhistory_len,\n\u001b[0;32m      9\u001b[0m     predict_len\u001b[38;5;241m=\u001b[39mpredict_len,\n\u001b[0;32m     10\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     11\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path,\n\u001b[0;32m     12\u001b[0m     save_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thoma\\Desktop\\Diffusion\\trainer.py:53\u001b[0m, in \u001b[0;36mtrain_diffusion_model_conditional\u001b[1;34m(data_x, score_net, optimizer, num_diffusion_timesteps, batch_size, num_epochs, history_len, predict_len, device, checkpoint_path, save_every)\u001b[0m\n\u001b[0;32m     51\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 53\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     55\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(losses)\n\u001b[0;32m     56\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_diffusion_model_conditional(\n",
    "    data_x=data,\n",
    "    score_net=model,\n",
    "    optimizer=optimizer,\n",
    "    num_diffusion_timesteps=num_diffusion_timesteps,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    history_len=history_len,\n",
    "    predict_len=predict_len,\n",
    "    device=device,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    save_every=100\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
